setwd("~/Documents/Documents – Patrycja’s MacBook Air/BigData/project/exam")
library(party)
library(DBI)
library(RMySQL)
library(tidyverse)
library(textstem)
library(gmodels)
library(tm)
library(wordcloud)
library(e1071)
library(dplyr)
library(strucchange)
#connection to MySQL
conMySQL <- dbConnect(MySQL(), dbname="hotel_reviews", user="root", password= "kurczak1", host="localhost")
#retreiveing data from DB, there are 2 ways = R function or stored procedure
data <- dbGetQuery(conMySQL, "CALL getAllReviews();")
#data <- dbReadTable(conMySQL, "cleaned_data", fileEncoding="UTF-8",  stringsAsFactors=TRUE)
#dataPositive <- dbGetQuery(conMySQL, "CALL getReviewsByLabel('positive');")
#removing sentences with less than 3 words
data <- data[sapply(gregexpr("\\W+", data$review), length) >3,]
#sampling my data
sample <- sample.int(n = nrow(data), size = floor(.11*nrow(data)), replace = F)
data = data[sample,]
data$label <- as.factor(data$label)
summary(data)
### CLEANING
corpus <- Corpus(VectorSource(data$review))
cleanCorpus <- corpus %>%
#tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, myStopwords) %>%
tm_map(stripWhitespace)
#expanding stopwords list with words that occur both in positive as in negative reviews
myStopwords<- c(stopwords("english"),"hotel","room","staff","t","the","breakfast")
cleanCorpus <- tm_map(cleanCorpus, removeWords, myStopwords)
#lemmatization
lemmatize_words(cleanCorpus)
cleanCorpusDtm <- DocumentTermMatrix(cleanCorpus)
#dividing data into train and test 70% / 30%
n <- nrow(data)
raw.text.train <- data[1:round(.7 * n),]
raw.text.test  <- data[(round(.3 * n)+1):n,]
nn <- length(cleanCorpus)
clean.corpus.train <- cleanCorpus[1:round(.7 * nn)]
clean.corpus.test  <- cleanCorpus[(round(.3 * nn)+1):nn]
nnn <- nrow(cleanCorpusDtm)
clean.corpus.dtm.train <- cleanCorpusDtm[1:round(.7 * nnn),]
clean.corpus.dtm.test  <- cleanCorpusDtm[(round(.3 * nnn)+1):nnn,]
#creating wordclouds from train data
wordcloud(clean.corpus.train, min.freq = 50, max.words = 50, random.order = FALSE)
positive <- subset(raw.text.train, label == "positive")
negative <- subset(raw.text.train, label == "negative")
wordcloud(positive$review, max.words = 30, scale = c(3, 0.5))
wordcloud(negative$review, max.words = 30, scale = c(3, 0.5))
#rmeoving terms that have frequency lower than 20
freq.terms <- findFreqTerms(clean.corpus.dtm.train, 20)
clean.corpus.dtm.freq.train <- DocumentTermMatrix(clean.corpus.train, list(dictionary = freq.terms))
clean.corpus.dtm.freq.test  <- DocumentTermMatrix(clean.corpus.test, list(dictionary = freq.terms))
str(clean.corpus.dtm.freq.train)
#removing sparse items - words that do not occur often
clean.corpus.dtm.freq.train<- removeSparseTerms(clean.corpus.dtm.freq.train, 0.99)
clean.corpus.dtm.freq.test <- removeSparseTerms(clean.corpus.dtm.freq.test, 0.99)
#creatin a function that converts the cells to be categorical instead of numerical 0 -> no and 1 -> yes
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return(x)
}
#applying the function to matrix
clean.corpus.dtm.freq.train <- apply(clean.corpus.dtm.freq.train, MARGIN = 2, convert_counts)
clean.corpus.dtm.freq.test <- apply(clean.corpus.dtm.freq.test, MARGIN = 2, convert_counts)
#training the nb classifier
naive.classifer <- naiveBayes(clean.corpus.dtm.freq.train, raw.text.train$label, laplace = 1)
#predicition
naive.pred <- predict(naive.classifer, clean.corpus.dtm.freq.test)
#confusion matrix
xtable = CrossTable(naive.pred, raw.text.test$label,
prop.chisq = FALSE,
prop.t = FALSE,
dnn = c('predicted', 'actual'))
#################### solution to fix the error in glm() & tree
n <- nrow(clean.corpus.dtm.freq.train)
clean.corpus.dtm.freq.train2 <- clean.corpus.dtm.freq.train[1:round(.7 * n), ]
raw.text.train2  <- raw.text.train[1:round(.7 * n),]
clean.corpus.dtm.freq.test2  <- clean.corpus.dtm.freq.train[(round(.3 * n)+1):n, ]
raw.text.test2  <- raw.text.train[(round(.3 * n)+1):n, ]
##################
#logistic
#creating df for logistic model
trainLogistic <- cbind(clean.corpus.dtm.freq.train2, Label=raw.text.train2$label)
trainLogistic <- as.data.frame(trainLogistic)
testLogistic <- cbind(clean.corpus.dtm.freq.test2, Label=raw.text.test2$label)
testLogistic <- as.data.frame(testLogistic)
#logistic regression model
log_model <- glm(Label~., data=trainLogistic, family=binomial(link="logit"))
#prediction
log.pred <- predict(log_model, newdata=testLogistic, type="response")
#confusion matrix
table(raw.text.test$label, log.pred>.5)
library(party)
library(DBI)
library(RMySQL)
library(tidyverse)
library(textstem)
library(gmodels)
library(tm)
library(wordcloud)
library(e1071)
library(dplyr)
library(strucchange)
#connection to MySQL
conMySQL <- dbConnect(MySQL(), dbname="hotel_reviews", user="root", password= "kurczak1", host="localhost")
#retreiveing data from DB, there are 2 ways = R function or stored procedure
data <- dbGetQuery(conMySQL, "CALL getAllReviews();")
#removing sentences with less than 3 words
data <- data[sapply(gregexpr("\\W+", data$review), length) >3,]
#sampling my data
sample <- sample.int(n = nrow(data), size = floor(.11*nrow(data)), replace = F)
data = data[sample,]
data$label <- as.factor(data$label)
summary(data)
corpus <- Corpus(VectorSource(data$review))
cleanCorpus <- corpus %>%
#tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, myStopwords) %>%
tm_map(stripWhitespace)
#expanding stopwords list with words that occur both in positive as in negative reviews
myStopwords<- c(stopwords("english"),"hotel","room","staff","t","the","breakfast")
cleanCorpus <- tm_map(cleanCorpus, removeWords, myStopwords)
#lemmatization
lemmatize_words(cleanCorpus)
cleanCorpusDtm <- DocumentTermMatrix(cleanCorpus)
#dividing data into train and test 70% / 30%
n <- nrow(data)
raw.text.train <- data[1:round(.7 * n),]
raw.text.test  <- data[(round(.3 * n)+1):n,]
nn <- length(cleanCorpus)
clean.corpus.train <- cleanCorpus[1:round(.7 * nn)]
clean.corpus.test  <- cleanCorpus[(round(.3 * nn)+1):nn]
nnn <- nrow(cleanCorpusDtm)
clean.corpus.dtm.train <- cleanCorpusDtm[1:round(.7 * nnn),]
clean.corpus.dtm.test  <- cleanCorpusDtm[(round(.3 * nnn)+1):nnn,]
#creating wordclouds from train data
wordcloud(clean.corpus.train, min.freq = 50, max.words = 50, random.order = FALSE)
positive <- subset(raw.text.train, label == "positive")
#rmeoving terms that have frequency lower than 20
freq.terms <- findFreqTerms(clean.corpus.dtm.train, 20)
clean.corpus.dtm.freq.train <- DocumentTermMatrix(clean.corpus.train, list(dictionary = freq.terms))
clean.corpus.dtm.freq.test  <- DocumentTermMatrix(clean.corpus.test, list(dictionary = freq.terms))
str(clean.corpus.dtm.freq.train)
#removing sparse items - words that do not occur often
clean.corpus.dtm.freq.train<- removeSparseTerms(clean.corpus.dtm.freq.train, 0.99)
clean.corpus.dtm.freq.test <- removeSparseTerms(clean.corpus.dtm.freq.test, 0.99)
#creatin a function that converts the cells to be categorical instead of numerical 0 -> no and 1 -> yes
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return(x)
}
#applying the function to matrix
clean.corpus.dtm.freq.train <- apply(clean.corpus.dtm.freq.train, MARGIN = 2, convert_counts)
clean.corpus.dtm.freq.test <- apply(clean.corpus.dtm.freq.test, MARGIN = 2, convert_counts)
#training the nb classifier
naive.classifer <- naiveBayes(clean.corpus.dtm.freq.train, raw.text.train$label, laplace = 1)
#predicition
naive.pred <- predict(naive.classifer, clean.corpus.dtm.freq.test)
#confusion matrix
xtable = CrossTable(naive.pred, raw.text.test$label,
prop.chisq = FALSE,
prop.t = FALSE,
dnn = c('predicted', 'actual'))
View(naive.classifer)
#################### solution to fix the error in glm() & tree
n <- nrow(clean.corpus.dtm.freq.train)
clean.corpus.dtm.freq.train2 <- clean.corpus.dtm.freq.train[1:round(.7 * n), ]
raw.text.train2  <- raw.text.train[1:round(.7 * n),]
clean.corpus.dtm.freq.test2  <- clean.corpus.dtm.freq.train[(round(.3 * n)+1):n, ]
raw.text.test2  <- raw.text.train[(round(.3 * n)+1):n, ]
#logistic
#creating df for logistic model
trainLogistic <- cbind(clean.corpus.dtm.freq.train2, Label=raw.text.train2$label)
trainLogistic <- as.data.frame(trainLogistic)
testLogistic <- cbind(clean.corpus.dtm.freq.test2, Label=raw.text.test2$label)
testLogistic <- as.data.frame(testLogistic)
#logistic regression model
log_model <- glm(Label~., data=trainLogistic, family=binomial(link="logit"))
#prediction
log.pred <- predict(log_model, newdata=testLogistic, type="response")
#confusion matrix
table(raw.text.test$label, log.pred>.5)
#prediction
log.pred <- predict(log_model, newdata=testLogistic, type="response")
#confusion matrix
table(raw.text.test2$label, log.pred>.5)
#coefficients
summary(log_model)
#Decision tree
tree = ctree(Label~., data = trainLogistic)
predictions = predict(tree, testLogistic)
table(predictions, raw.text.test2$label)
conMySQL <- dbConnect(MySQL(), dbname="hotel_reviews", user="root", password= "kurczak1", host="localhost")
data <- dbGetQuery(conMySQL, "CALL getAllReviews();")
data$label <- as.factor(data$label)
sample <- sample.int(n = nrow(data), size = floor(.05*nrow(data)), replace = F)
data = data[sample,]
data$label <- as.factor(data$label)
#rownames(data) <- NULL
data <- data[sapply(gregexpr("\\W+", data$review), length) >3,]
#setting the number of handwritten reviews
n_reviews_new = 5
n <- nrow(data)
#creating vectors from new reviews and labels
new_reviews = c("The stay was awful, my room was dirty and it was very noisy in the night. I would not recommend this hotel to anyone!",
"I really liked the service and my room view. the location was central, 5 minutes walk to the city center. The room wasnt the most modern, however for this price it was good value.",
"I enjoyed my stay. Room was well equipped and the breakfast was really nice! Everything was as stated on the website, nothing to complain on. Definietly would recommend!",
"Bad", "very nice")
new_label = c("negative","positive","positive","negative","positive")
#iterating through data and replacing last reviews with handwritten ones
j = 1
for (i in (n-n_reviews_new):(n-1)){
data[i,1] = new_reviews[j]
data[i,2] = new_label[j]
j = j + 1
}
#creating corpus
corpus <- Corpus(VectorSource(data$review))
#cleaning the corpus
cleanCorpus <- corpus %>%
#tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
#removing stopwrods and custom words
myStopwords<- c(stopwords("english"),"hotel","room","Room","staff","the","The","breakfast")
cleanCorpus <- tm_map(cleanCorpus, removeWords, myStopwords)
#lematization
lemmatize_words(cleanCorpus)
#creating DTM
cleanCorpusDtm <- DocumentTermMatrix(cleanCorpus)
#splitting the data into train and validation - in this case validation is the last five rows of my data
n <- nrow(data)
raw.text.train <- data[1:as.integer(0.7*n),]
raw.text.validation  <- data[(n-n_reviews_new):(n-1) ,]
nn <- length(cleanCorpus)
clean.corpus.train <- cleanCorpus[1:(as.integer(0.7*nn))]
clean.corpus.validation  <- cleanCorpus[(nn-n_reviews_new):(nn-1)]
nnn <- nrow(cleanCorpusDtm)
clean.corpus.dtm.train <- cleanCorpusDtm[1:as.integer(0.7*nnn),]
clean.corpus.dtm.validation  <- cleanCorpusDtm[(nnn-n_reviews_new):(nnn-1) ,]
#removing terms that do not appear often
freq.terms <- findFreqTerms(clean.corpus.dtm.train, 20)
clean.corpus.dtm.freq.train <- DocumentTermMatrix(clean.corpus.train, list(dictionary = freq.terms))
clean.corpus.dtm.freq.validation  <- DocumentTermMatrix(clean.corpus.validation, list(dictionary = freq.terms))
#removing sparse terms
clean.corpus.dtm.freq.train <- removeSparseTerms(clean.corpus.dtm.freq.train, 0.99)
clean.corpus.dtm.freq.validation <- removeSparseTerms(clean.corpus.dtm.freq.validation, 0.99)
#creatin a function that converts the cells to be categorical instead of numerical 0 -> no and 1 -> yes
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return(x)
}
#applying the function to matrix
clean.corpus.dtm.freq.train <- apply(clean.corpus.dtm.freq.train, MARGIN = 2, convert_counts)
clean.corpus.dtm.freq.validation  <- apply(clean.corpus.dtm.freq.validation, MARGIN = 2, convert_counts)
#training the classifier
modelNaiveBayes <- naiveBayes(clean.corpus.dtm.freq.train, raw.text.train$label)
#predicting on handwritten reviews
text.pred <- predict(modelNaiveBayes, clean.corpus.dtm.freq.validation)
xtable = CrossTable(text.pred, raw.text.validation$label,
prop.chisq = FALSE,
prop.t = FALSE,
dnn = c('predicted', 'actual'))
View(log_model)
log_model
summary(log_model)
review <- read.csv(review7.csv)
setwd("~/Documents/Documents – Patrycja’s MacBook Air/BigData/project/exam")
review <- read.csv("review7.csv")
View(review)
review <- read.csv("review7.csv")
review <- read.csv("review7.csv", header = FALSE)
review <- read.csv("review7.csv", header = TRUE)
View(review)
FALSE
review <- read.csv("review7.csv", header = FALSE, sep=" ")
View(review)
conMySQL <- dbConnect(MySQL(), dbname="hotel_reviews", user="root", password= "kurczak1", host="localhost")
data <- dbGetQuery(conMySQL, "CALL getAllReviews();")
data$label <- as.factor(data$label)
sample <- sample.int(n = nrow(data), size = floor(.05*nrow(data)), replace = F)
data = data[sample,]
data$label <- as.factor(data$label)
#rownames(data) <- NULL
data <- data[sapply(gregexpr("\\W+", data$review), length) >3,]
#setting the number of handwritten reviews
n_reviews_new = 2
n <- nrow(data)
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot. Wendy's house was spectacular, we loved every minute there. We were a group of 12 people including an infant, and there was plenty of space for all of us. The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled. Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queen's Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended",
)
new_label = c("positive","positive")
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot. Wendy's house was spectacular, we loved every minute there. We were a group of 12 people including an infant, and there was plenty of space for all of us. The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queen's Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot. Wendy's house was spectacular, we loved every minute there. We were a group of 12 people including an infant, and there was plenty of space for all of us. The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queen's Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot. Wendy's house was spectacular, we loved every minute there. We were a group of 12 people including an infant, and there was plenty of space for all of us. The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queen's Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot. Wendy's house was spectacular, we loved every minute there. We were a group of 12 people including an infant, and there was plenty of space for all of us. The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queen's Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot.
Wendy's house was spectacular, we loved every minute there.
We were a group of 12 people including an infant, and there was plenty of space for all of us.
The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queen's Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot.
Wendy's house was spectacular, we loved every minute there.
We were a group of 12 people including an infant, and there was plenty of space for all of us.
The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queen's Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot.
Wendy's house was spectacular, we loved every minute there.
We were a group of 12 people including an infant, and there was plenty of space for all of us.
The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queen's Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot.
Wendy's house was spectacular, we loved every minute there.
We were a group of 12 people including an infant, and there was plenty of space for all of us.
The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queen's Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
new_reviews = c("I wish we'd never left this beautiful spot.
Wendy's house was spectacular, we loved every minute there.
We were a group of 12 people including an infant, and there was plenty of space for all of us.
The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queens Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
reviews = c("I wish we'd never left this beautiful spot.
Wendy's house was spectacular, we loved every minute there.
We were a group of 12 people including an infant, and there was plenty of space for all of us.
The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queens Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
reviews = c("I wish wed never left this beautiful spot.
Wendy's house was spectacular, we loved every minute there.
We were a group of 12 people including an infant, and there was plenty of space for all of us.
The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queens Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
#creating vectors from new reviews and labels
reviews = c("I wish wed never left this beautiful spot.
Wendy's house was spectacular, we loved every minute there.
We were a group of 12 people including an infant, and there was plenty of space for all of us.
The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!",
"Our stay in this beautiful home was fantastic! The house is located in a prime location near some of the island's best beaches and other attractions including Queens Bath, Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended"
review1 <- as.character("I wish wed never left this beautiful spot.
Wendy's house was spectacular, we loved every minute there.
We were a group of 12 people including an infant, and there was plenty of space for all of us.
The views from the terrace were beautiful, short walk to the beach and the house was equipped with everything we could possibly need. Wendy was so responsive and gracious, we felt so spoiled.
Thank you for everything Wendy, we hope to come back one day!")
review2 <- as.character("Our stay in this beautiful home was fantastic!
The house is located in a prime location near some
of the island's best beaches and other attractions including Queens Bath,
Hanalei, the Na Pali Coast, etc. Tammy is very kind and easy to work with and the home is clean and welcoming. Highly recommended")
#creating vectors from new reviews and labels
reviews = c(review1, review2)
#creating vectors from new reviews and labels
new_reviews = c(review1, review2)
new_label = c("positive","positive")
#iterating through data and replacing last reviews with handwritten ones
j = 1
for (i in (n-n_reviews_new):(n-1)){
data[i,1] = new_reviews[j]
data[i,2] = new_label[j]
j = j + 1
}
#creating corpus
corpus <- Corpus(VectorSource(data$review))
#cleaning the corpus
cleanCorpus <- corpus %>%
#tm_map(content_transformer(tolower)) %>%
tm_map(removePunctuation) %>%
tm_map(removeNumbers) %>%
tm_map(removeWords, stopwords(kind="en")) %>%
tm_map(stripWhitespace)
#removing stopwrods and custom words
myStopwords<- c(stopwords("english"),"hotel","room","Room","staff","the","The","breakfast")
cleanCorpus <- tm_map(cleanCorpus, removeWords, myStopwords)
#lematization
lemmatize_words(cleanCorpus)
#creating DTM
cleanCorpusDtm <- DocumentTermMatrix(cleanCorpus)
#splitting the data into train and validation - in this case validation is the last five rows of my data
n <- nrow(data)
raw.text.train <- data[1:as.integer(0.7*n),]
raw.text.validation  <- data[(n-n_reviews_new):(n-1) ,]
nn <- length(cleanCorpus)
clean.corpus.train <- cleanCorpus[1:(as.integer(0.7*nn))]
clean.corpus.validation  <- cleanCorpus[(nn-n_reviews_new):(nn-1)]
nnn <- nrow(cleanCorpusDtm)
clean.corpus.dtm.train <- cleanCorpusDtm[1:as.integer(0.7*nnn),]
clean.corpus.dtm.validation  <- cleanCorpusDtm[(nnn-n_reviews_new):(nnn-1) ,]
#removing terms that do not appear often
freq.terms <- findFreqTerms(clean.corpus.dtm.train, 20)
clean.corpus.dtm.freq.train <- DocumentTermMatrix(clean.corpus.train, list(dictionary = freq.terms))
clean.corpus.dtm.freq.validation  <- DocumentTermMatrix(clean.corpus.validation, list(dictionary = freq.terms))
#removing sparse terms
clean.corpus.dtm.freq.train <- removeSparseTerms(clean.corpus.dtm.freq.train, 0.99)
clean.corpus.dtm.freq.validation <- removeSparseTerms(clean.corpus.dtm.freq.validation, 0.99)
#creatin a function that converts the cells to be categorical instead of numerical 0 -> no and 1 -> yes
convert_counts <- function(x) {
x <- ifelse(x > 0, 1, 0)
x <- factor(x, levels = c(0, 1), labels = c("No", "Yes"))
return(x)
}
#applying the function to matrix
clean.corpus.dtm.freq.train <- apply(clean.corpus.dtm.freq.train, MARGIN = 2, convert_counts)
clean.corpus.dtm.freq.validation  <- apply(clean.corpus.dtm.freq.validation, MARGIN = 2, convert_counts)
#training the classifier
modelNaiveBayes <- naiveBayes(clean.corpus.dtm.freq.train, raw.text.train$label)
View(raw.text.validation)
#predicting on handwritten reviews
text.pred <- predict(modelNaiveBayes, clean.corpus.dtm.freq.validation)
xtable = CrossTable(text.pred, raw.text.validation$label,
prop.chisq = FALSE,
prop.t = FALSE,
dnn = c('predicted', 'actual'))
#training the classifier
modelNaiveBayes <- naiveBayes(clean.corpus.dtm.freq.train, raw.text.train$label)
#predicting on handwritten reviews
text.pred <- predict(modelNaiveBayes, clean.corpus.dtm.freq.validation)
xtable = CrossTable(text.pred, raw.text.validation$label,
prop.chisq = FALSE,
prop.t = FALSE,
dnn = c('predicted', 'actual'))
View(modelNaiveBayes)
View(naive.classifer)
clean.corpus.validation[[3]]$content
clean.corpus.validation[[2]]$content
table(text.pred, raw.text.validation$label)
